{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f27b84",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-21T11:49:57.324616Z",
     "end_time": "2023-08-21T11:50:00.779726Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19975d0f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-21T11:50:00.782078Z",
     "end_time": "2023-08-21T11:50:00.795726Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(os.path.join(\"..\",\"processed_label_data.csv\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T11:50:00.797727Z",
     "end_time": "2023-08-21T11:50:00.875727Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "raw_df[\"class_ids\"] = raw_df[\"class_ids\"].apply(ast.literal_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T11:50:00.876728Z",
     "end_time": "2023-08-21T11:50:00.971771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ae_filtered_df = raw_df[raw_df[\"class_ids\"].apply(lambda x: 0 in x)].sample(500)\n",
    "nf_filtered_df = raw_df[raw_df[\"class_ids\"].apply(lambda x: 14 in x)].sample(500)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T11:50:00.973772Z",
     "end_time": "2023-08-21T11:50:00.986771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 600, 600, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 600, 600, 16)         3088      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 600, 600, 16)         64        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 600, 600, 16)         0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 300, 300, 16)         0         ['re_lu[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 300, 300, 16)         16400     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 300, 300, 16)         64        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 300, 300, 16)         0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 300, 300, 32)         32800     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 300, 300, 32)         32800     ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 300, 300, 32)         128       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 300, 300, 32)         128       ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 300, 300, 32)         0         ['batch_normalization_1[0][0]'\n",
      "                                                                    , 'batch_normalization_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 300, 300, 32)         0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 300, 300, 32)         65568     ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 300, 300, 32)         128       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 300, 300, 32)         0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 150, 150, 32)         0         ['re_lu_3[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 150, 150, 32)         65568     ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 150, 150, 32)         128       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 150, 150, 32)         0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 150, 150, 64)         131136    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 150, 150, 64)         131136    ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 150, 150, 64)         256       ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 150, 150, 64)         256       ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 150, 150, 64)         0         ['batch_normalization_5[0][0]'\n",
      "                                                                    , 'batch_normalization_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 150, 150, 64)         0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 150, 150, 64)         262208    ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 150, 150, 64)         256       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 150, 150, 64)         0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 75, 75, 64)           0         ['re_lu_6[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 64)                   0         ['max_pooling2d_2[0][0]']     \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 512)                  33280     ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 512)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 256)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  32896     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    129       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 939745 (3.58 MB)\n",
      "Trainable params: 939041 (3.58 MB)\n",
      "Non-trainable params: 704 (2.75 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Dropout, MaxPool2D, Dense, Input, GlobalAveragePooling2D, BatchNormalization, Add, ReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import plot_model\n",
    "def build_model(inputs, kernel_size, n_classes):\n",
    "    x = Conv2D(filters=16, kernel_size=kernel_size, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x = residual_block(x, 16, kernel_size)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x = residual_block(x, 32, kernel_size)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dense(n_classes, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=x)\n",
    "\n",
    "\n",
    "def residual_block(x, filters, kernel_size, strides = 1):\n",
    "    shortcut = x\n",
    "\n",
    "    shortcut = Conv2D(filters=2*filters, kernel_size=kernel_size, strides=strides, padding=\"same\")(shortcut)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters=2*filters, kernel_size=kernel_size, strides=strides, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Add()([shortcut, x])\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "model = build_model(Input(shape=(600, 600, 3)), kernel_size=8, n_classes=1)\n",
    "model.summary()\n",
    "optimizer = RMSprop(learning_rate = 0.001)\n",
    "plot_model(to_file=\"model.png\", model=model)\n",
    "model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T11:50:00.992771Z",
     "end_time": "2023-08-21T11:50:01.400802Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "22/25 [=========================>....] - ETA: 1:38 - loss: 0.7062 - accuracy: 0.5270"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\4054252707.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     76\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 77\u001B[1;33m \u001B[0mtrain_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11096\\4054252707.py\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, x, y, n_splits, batch_size, test_size, random_state, n_epochs, min_learning_rate, lr_decay_factor)\u001B[0m\n\u001B[0;32m     59\u001B[0m         \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_ids\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_ids\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         histories.append(model.fit(img_train, y_train, batch_size = 32,\n\u001B[0m\u001B[0;32m     62\u001B[0m                                    \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mn_epochs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m                                    callbacks=[ReduceLROnPlateau(monitor=\"val_loss\", factor=lr_decay_factor,\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1740\u001B[0m                         ):\n\u001B[0;32m   1741\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1742\u001B[1;33m                             \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1743\u001B[0m                             \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1744\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    823\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    824\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 825\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    826\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    855\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    856\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 857\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_no_variable_creation_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    858\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variable_creation_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    859\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    146\u001B[0m       (concrete_function,\n\u001B[0;32m    147\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m--> 148\u001B[1;33m     return concrete_function._call_flat(\n\u001B[0m\u001B[0;32m    149\u001B[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m    150\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs)\u001B[0m\n\u001B[0;32m   1347\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1348\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1349\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_build_call_outputs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_inference_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1350\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[0;32m   1351\u001B[0m         \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m    194\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mrecord\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop_recording\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    195\u001B[0m           \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_bound_context\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 196\u001B[1;33m             outputs = self._bound_context.call_function(\n\u001B[0m\u001B[0;32m    197\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    198\u001B[0m                 \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py\u001B[0m in \u001B[0;36mcall_function\u001B[1;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[0;32m   1455\u001B[0m     \u001B[0mcancellation_context\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcancellation\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1456\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcancellation_context\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1457\u001B[1;33m       outputs = execute.execute(\n\u001B[0m\u001B[0;32m   1458\u001B[0m           \u001B[0mname\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"utf-8\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1459\u001B[0m           \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnum_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     51\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     54\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     55\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "class MaxAccuracy(Callback):\n",
    "    def __init__(self):\n",
    "        super(MaxAccuracy, self).__init__()\n",
    "        self.max_train_accuracy = 0.0\n",
    "        self.max_val_accuracy = 0.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_accuracy = logs['accuracy']\n",
    "        val_accuracy = logs['val_accuracy']\n",
    "        if train_accuracy > self.max_train_accuracy:\n",
    "            self.max_train_accuracy = train_accuracy\n",
    "        if val_accuracy > self.max_val_accuracy:\n",
    "            self.max_val_accuracy = val_accuracy\n",
    "        print(\n",
    "            f\" Max Train Accuracy: {self.max_train_accuracy:.4f}, Max Validation Accuracy: {self.max_val_accuracy:.4f}\")\n",
    "\n",
    "# def custom_data_generator(x, y, batch_size):\n",
    "#     num_samples = len(x)\n",
    "#     steps_per_epoch = num_samples // batch_size\n",
    "#\n",
    "#     for i in range(steps_per_epoch):\n",
    "#         start_idx = i * batch_size\n",
    "#         end_idx = (i + 1) * batch_size\n",
    "#\n",
    "#         batch_filenames = x[start_idx:end_idx]\n",
    "#         batch_labels = y[start_idx:end_idx]\n",
    "#\n",
    "#         batch_images = []\n",
    "#         for filename in batch_filenames:\n",
    "#             img = cv2.imread(os.path.join(\"..\", \"dataLake\", filename+\".png\"))\n",
    "#             img = img/255\n",
    "#             batch_images.append(img)\n",
    "#\n",
    "#         yield np.array(batch_images), np.array(batch_labels)\n",
    "\n",
    "\n",
    "def train_model(model, x, y, n_splits=2, batch_size=64, test_size=0.2, random_state=47, n_epochs=20,\n",
    "                min_learning_rate=0.0000001, lr_decay_factor=0.8):\n",
    "    splitter = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    aug_set_id = 0\n",
    "    histories = []\n",
    "    max_accuracy = MaxAccuracy()\n",
    "    for train_ids, test_ids in splitter.split(x, y):\n",
    "        checkpoint = ModelCheckpoint(\"model_\" + str(aug_set_id) + \".h5\", monitor=\"val_accuracy\",\n",
    "                                     save_best_only=True, model=\"max\")\n",
    "        aug_set_id = aug_set_id + 1\n",
    "\n",
    "        x_train, x_test = np.asarray(x[train_ids]), np.asarray(x[test_ids])\n",
    "\n",
    "\n",
    "        base_path = os.path.join(\"..\", \"dataLake\")\n",
    "        img_train = np.asarray([cv2.imread(os.path.join(base_path, x+\".png\")) for x in x_train]) / 255\n",
    "        img_test = np.asarray([cv2.imread(os.path.join(base_path, x+\".png\")) for x in x_test]) / 255\n",
    "        y_train, y_test = np.asarray(y[train_ids]), np.asarray(y[test_ids])\n",
    "\n",
    "        histories.append(model.fit(img_train, y_train, batch_size = 32,\n",
    "                                   epochs=n_epochs, validation_data=(img_test, y_test),\n",
    "                                   callbacks=[ReduceLROnPlateau(monitor=\"val_loss\", factor=lr_decay_factor,\n",
    "                                                                patience=2, min_lr=min_learning_rate), checkpoint, max_accuracy]))\n",
    "\n",
    "    return histories\n",
    "\n",
    "x1 = ae_filtered_df[\"image_id\"].to_list()\n",
    "x2 = nf_filtered_df[\"image_id\"].to_list()\n",
    "x1.extend(x2)\n",
    "x = np.asarray(x1)\n",
    "\n",
    "y = [1]*500\n",
    "y.extend([0]*500)\n",
    "y = np.asarray(y)\n",
    "\n",
    "train_model(model, x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T10:26:22.545973Z",
     "end_time": "2023-08-21T10:39:11.648737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_df[raw_df[\"image_id\"] == \"469bd3f41e12a8f03a8ef0ce191743ce\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-21T10:30:20.794395Z",
     "end_time": "2023-08-21T10:30:20.814397Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
